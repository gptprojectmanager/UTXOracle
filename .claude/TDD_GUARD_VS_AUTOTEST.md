# üîç TDD Guard vs Auto-Test - Analisi Complementariet√†

## üìä Cosa Fa Ciascuno

### **TDD Guard** (gi√† installato)

**Scopo**: ENFORCEMENT (blocca violazioni TDD)

**Funzionamento**:
```
Claude tenta: Write production code
         ‚Üì
TDD Guard: ‚ùå BLOCKED! Nessun test failing
         ‚Üì
Claude: Scrive test RED first
         ‚Üì
TDD Guard: ‚úÖ OK, procedi
```

**Cosa BLOCCA**:
- ‚ùå Implementation senza test failing (RED first)
- ‚ùå Over-implementation (oltre test requirements)
- ‚ùå Multiple test additions (un test alla volta)

**Cosa NON FA**:
- ‚ùå Non esegue test
- ‚ùå Non verifica che test passino
- ‚ùå Non d√† feedback su test failures

---

### **Auto-Test** (proposto, non installato)

**Scopo**: AUTOMATION (esegue test automaticamente)

**Funzionamento**:
```
Claude modifica: live/backend/zmq_listener.py
         ‚Üì
Auto-Test: Rileva modifica Python
         ‚Üì
Auto-Test: Esegue pytest tests/test_live/test_zmq_listener.py
         ‚Üì
Output: ‚úÖ 5 passed / ‚ùå 2 failed
         ‚Üì
Claude: Vede failures, fixxa
```

**Cosa FA**:
- ‚úÖ Esegue test automaticamente dopo edit
- ‚úÖ Mostra output test a Claude
- ‚úÖ Feedback immediato su failures

**Cosa NON FA**:
- ‚ùå Non blocca niente
- ‚ùå Non enforce TDD workflow
- ‚ùå Solo esecuzione, no enforcement

---

## ü§ù Sono Complementari!

| Aspetto | TDD Guard | Auto-Test | Complementari? |
|---------|-----------|-----------|----------------|
| **Enforce test-first** | ‚úÖ | ‚ùå | S√¨ - TDD Guard forza, Auto-test aiuta |
| **Esegue test** | ‚ùå | ‚úÖ | S√¨ - TDD Guard non esegue, Auto-test s√¨ |
| **Blocca violazioni** | ‚úÖ | ‚ùå | S√¨ - enforcement vs automation |
| **Feedback loop** | ‚ùå | ‚úÖ | S√¨ - Auto-test chiude loop |

---

## üéØ Workflow Completo (Con Entrambi)

### **Scenario: Aggiungere feature ZMQ listener**

```python
# Step 1: Claude tenta implementazione
Write: live/backend/zmq_listener.py
  def listen_transactions():
      # Implementation...

# TDD Guard:
‚ùå BLOCKED! No failing test found for zmq_listener.py
   Write test first (RED), then implementation (GREEN)

# Step 2: Claude scrive test
Write: tests/test_live/test_zmq_listener.py
  def test_listen_transactions():
      # Test implementation
      assert zmq_listener.listen_transactions() == expected

# TDD Guard:
‚úÖ OK - Test file created

# Auto-Test (se attivo):
üß™ Running: pytest tests/test_live/test_zmq_listener.py
‚ùå FAILED - ImportError: No module 'zmq_listener'
   (Test RED - come previsto!)

# Step 3: Claude implementa (TDD Guard permette, test √® RED)
Write: live/backend/zmq_listener.py
  def listen_transactions():
      return []  # Minimal implementation

# Auto-Test:
üß™ Running: pytest tests/test_live/test_zmq_listener.py
‚úÖ PASSED - 1 test passed

# Step 4: Refactor (opzionale)
Edit: live/backend/zmq_listener.py
  # Improve implementation

# Auto-Test:
üß™ Running: pytest tests/test_live/test_zmq_listener.py
‚úÖ PASSED - Still green!
```

**Risultato**:
- TDD Guard: Enforz√≤ RED ‚Üí GREEN workflow
- Auto-Test: Diede feedback immediato su ogni step

---

## ‚öñÔ∏è UTXOracle: Serve Auto-Test?

### **Considerazioni KISS/YAGNI**

| Pro | Contro |
|-----|--------|
| ‚úÖ Feedback automatico immediato | ‚ùå Token/tempo extra per ogni modifica |
| ‚úÖ Scopre errori subito | ‚ùå pytest pu√≤ essere lento (>2s) |
| ‚úÖ Simula CI locale | ‚ùå Frontend JS non ha test setup |
| ‚úÖ Claude vede failures senza chiedere | ‚ùå Agenti gi√† testano manualmente quando serve |

### **Stato Attuale UTXOracle**

```
Backend Python:
  ‚Ä¢ TDD Guard: ‚úÖ Attivo (enforcement)
  ‚Ä¢ Auto-test: ‚ùå Non configurato
  ‚Ä¢ Test command: uv run pytest
  ‚Ä¢ Test speed: ~2-3s (ok per manual, lento per auto)

Frontend JS:
  ‚Ä¢ TDD Guard: ‚ùå Disabilitato (frontend/**/*.js ignorato)
  ‚Ä¢ Auto-test: ‚ùå Non serve (no test setup, vanilla JS)
  ‚Ä¢ Test command: Nessuno (no Jest/Vitest)

Agenti:
  ‚Ä¢ Gi√† eseguono pytest manualmente quando necessario
  ‚Ä¢ TDD Guard li forza a scrivere test first
```

---

## üí° Raccomandazione

### **KISS Approach (Raccomandato per ora)**

**Mantieni solo TDD Guard** ‚úÖ

**Motivi**:
1. TDD Guard gi√† enforce discipline (obiettivo principale)
2. Auto-test aggiunge overhead (2-3s √ó 10 modifiche = 30s)
3. Agenti gi√† eseguono `uv run pytest` quando serve
4. Frontend non ha test (auto-test inutile)
5. YAGNI - no complessit√† prematura

**Workflow attuale (funziona bene)**:
```
1. TDD Guard blocca ‚Üí Claude scrive test
2. Claude esegue: uv run pytest tests/test_module.py
3. Vede output, fixa se fallisce
4. Procede
```

---

### **Quando Aggiungere Auto-Test** (Futuro)

Aggiungi auto-test SOLO SE:

1. **Test diventano veloci** (<500ms)
   - Dopo refactor Rust/Cython
   - Con test paralleli
   
2. **Sviluppo frontend intenso**
   - Setup Jest/Vitest
   - Test component Canvas/Three.js
   
3. **CI/CD locale importante**
   - Pre-commit automation
   - Continuous feedback required

4. **Pi√π di 100 test**
   - Feedback loop manuale troppo lento
   - Auto-test risparmia tempo

---

## üìù Implementazione Auto-Test (Se Serve)

### **Versione Python per UTXOracle**

```python
#!/usr/bin/env python3
# .claude/hooks/auto-test.py

import os
import sys
import json
import subprocess
from pathlib import Path

def should_run_tests(file_path):
    """Check if file change should trigger tests"""
    
    # Only Python files
    if not file_path.endswith('.py'):
        return False
    
    # Skip non-test changes in specific dirs
    skip_dirs = ['archive/', 'historical_data/', '.venv/']
    if any(skip in file_path for skip in skip_dirs):
        return False
    
    return True

def find_test_file(file_path):
    """Find corresponding test file"""
    
    # If already a test file, run it
    if '/test_' in file_path or file_path.startswith('tests/'):
        return file_path
    
    # Map source file to test file
    # live/backend/zmq_listener.py ‚Üí tests/test_live/test_zmq_listener.py
    path = Path(file_path)
    
    if 'live/backend/' in file_path:
        test_file = f"tests/test_live/test_{path.name}"
    elif 'core/' in file_path:
        test_file = f"tests/test_core/test_{path.name}"
    else:
        # Default: tests/test_<filename>
        test_file = f"tests/test_{path.name}"
    
    return test_file if Path(test_file).exists() else None

def main():
    try:
        input_data = json.loads(sys.stdin.read())
        
        tool_name = input_data.get("tool_name", "")
        tool_input = input_data.get("tool_input", {})
        
        # Only trigger on Write/Edit
        if tool_name not in ["Write", "Edit", "MultiEdit"]:
            sys.exit(0)
        
        file_path = tool_input.get("file_path", "")
        
        if not should_run_tests(file_path):
            sys.exit(0)
        
        test_file = find_test_file(file_path)
        
        if not test_file:
            # No test file found, silent pass
            sys.exit(0)
        
        # Run tests
        result = subprocess.run(
            ["uv", "run", "pytest", test_file, "-v"],
            capture_output=True,
            text=True,
            timeout=10  # 10s max
        )
        
        # Show output to Claude
        output = {
            "hookSpecificOutput": {
                "hookEventName": "PostToolUse",
                "message": (
                    f"üß™ Auto-Test Results for {Path(file_path).name}:\n\n"
                    f"{result.stdout}\n"
                    f"{'‚úÖ PASSED' if result.returncode == 0 else '‚ùå FAILED'}"
                )
            }
        }
        
        print(json.dumps(output))
        sys.exit(0)
        
    except subprocess.TimeoutExpired:
        print(json.dumps({
            "hookSpecificOutput": {
                "message": "‚ö†Ô∏è  Tests timeout (>10s), skipped auto-run"
            }
        }))
        sys.exit(0)
    except Exception:
        # Fail open
        sys.exit(0)

if __name__ == "__main__":
    main()
```

**Configurazione**:
```json
{
  "hooks": {
    "PostToolUse": [{
      "matcher": "Write|Edit|MultiEdit",
      "hooks": [{
        "type": "command",
        "command": ".claude/hooks/auto-test.py"
      }]
    }]
  }
}
```

---

## üéØ Conclusione

### **Per UTXOracle OGGI**

‚úÖ **Mantieni TDD Guard** (enforcement)  
‚ùå **Defer Auto-Test** (YAGNI, overhead non giustificato)

**Motivo**: TDD Guard gi√† garantisce test-first, auto-test aggiunge poco valore con overhead significativo.

### **Aggiungi Auto-Test QUANDO**

- Test diventano veloci (<500ms)
- Setup test frontend (Jest)
- CI/CD locale diventa priorit√†
- >100 test nel progetto

